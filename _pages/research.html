---
layout: page
title: Research
subtitle: Research Topics
desc: Research Topics
permalink: /research/
---

<div class="projects">
  <div class="grid no-gutters">
    <div class="unit half">
      <div class="project">
        <h4 class="project-title"><a href="aed-by-cnn/">Weakly Supervised Audio Event Detection</a></h4>
        <img src="/assets/img/aed-by-cnn/fcn_model.jpg">
        <p>In this topic, we try to discover not only <strong>the sound events happened in an audio clip</strong> (clip-level information) but also <strong>the temporal positions of the detected sounds</strong> (frame-level information). Since creating frame-level annotated data can be extremely time-consuming, we proposed a model based on <strong>convolutional neural networks</strong> that relies on <strong>data with only clip-level labels (weakly supervised data) for training</strong>.</p>
      </div>
    </div>
    <div class="unit half">
      <div class="project">
        <h4 class="project-title"><a href="solo-transcription/">Guitar Solo Transcription</a></h4>
        <img src="/assets/img/solo-transcription/lick_7.png">
        <p>Given a clip of guitar solo, we tried to transcribe not only the melody but also the playing techniques, such as bend, vibrato, hammer-on, ..., that are used in the melody. Therefore, we designed a algorithm that can detect the appearance of playing techniques as well as doing note tracking.</p>
      </div>
    </div>
  </div><!-- grid -->
</div>